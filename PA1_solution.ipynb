{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef178144",
   "metadata": {},
   "source": [
    "We begin by importing required Python libraries for data manipulation, preprocessing, and dimensionality reduction (PCA). We also import defaultdict to help with hash table creation in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e8d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7515bf3c",
   "metadata": {},
   "source": [
    "We load the FMA metadata and filter the dataset to include only tracks from the \"medium\" subset. We then keep only the 8 most relevant genres and scale the feature values using StandardScaler. Additionally, we apply PCA to reduce the feature space to 50 components. Finally, we split the data into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05fddbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data prepared with kurtosis, all, and PCA feature sets for training, validation, and test.\n"
     ]
    }
   ],
   "source": [
    "#  Load metadata (tracks)\n",
    "df_tracks = pd.read_csv('tracks.csv', index_col=0, header=[0, 1])\n",
    "df_tracks = df_tracks[df_tracks[('set', 'subset')] == 'medium']\n",
    "\n",
    "# Filter for 8 genres\n",
    "genres = ['Hip-Hop', 'Pop', 'Folk', 'Rock', 'Experimental', 'International', 'Electronic', 'Instrumental']\n",
    "df_tracks = df_tracks[df_tracks[('track', 'genre_top')].isin(genres)]\n",
    "\n",
    "#  simplified split and genre columns to add\n",
    "df_tracks['split'] = df_tracks[('set', 'split')]\n",
    "df_tracks['genre'] = df_tracks[('track', 'genre_top')]\n",
    "\n",
    "#  Load features \n",
    "df_features = pd.read_csv('features.csv', index_col=0, header=[0, 1, 2])\n",
    "df_features.columns = ['_'.join(col).strip() for col in df_features.columns.values]\n",
    "\n",
    "#  USE/store/keep  only the tracks from filtered metadata\n",
    "df_features = df_features.loc[df_tracks.index]\n",
    "\n",
    "#  Create Feature Sets from the three options\n",
    "\n",
    "# a) Kurtosis only\n",
    "kurtosis_cols = [col for col in df_features.columns if 'kurtosis' in col]\n",
    "X_kurtosis = df_features[kurtosis_cols]\n",
    "\n",
    "# b) All features\n",
    "X_all = df_features.copy()\n",
    "\n",
    "# c) PCA-reduced (50 components)\n",
    "scaler = StandardScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_all)\n",
    "pca = PCA(n_components=50)\n",
    "X_pca = pd.DataFrame(pca.fit_transform(X_all_scaled), index=X_all.index)\n",
    "\n",
    "#  The Final Splits \n",
    "y = df_tracks['genre']\n",
    "\n",
    "splits = {\n",
    "    'train': df_tracks[df_tracks['split'] == 'training'],\n",
    "    'valid': df_tracks[df_tracks['split'] == 'validation'],\n",
    "    'test': df_tracks[df_tracks['split'] == 'test']\n",
    "}\n",
    "\n",
    "# Now we store all the data \n",
    "data = {}\n",
    "X_dict = {\n",
    "    'kurtosis': X_kurtosis,\n",
    "    'all': X_all,\n",
    "    'pca': X_pca\n",
    "}\n",
    "\n",
    "for key in X_dict.keys():\n",
    "    data[key] = {}\n",
    "    for split_name, df_split in splits.items():\n",
    "        idx = df_split.index\n",
    "        data[key][split_name] = {\n",
    "            'X': X_dict[key].loc[idx],\n",
    "            'y': y.loc[idx]\n",
    "        }\n",
    "\n",
    "# Extract arrays from 'data' to match the variable names from second snippet\n",
    "X_all_train = data['all']['train']['X'].values\n",
    "X_pca_train = data['pca']['train']['X'].values\n",
    "y_train = data['all']['train']['y'].values\n",
    "\n",
    "X_all_val = data['all']['valid']['X'].values\n",
    "X_pca_val = data['pca']['valid']['X'].values\n",
    "y_val = data['all']['valid']['y'].values\n",
    "\n",
    "X_all_test = data['all']['test']['X'].values\n",
    "X_pca_test = data['pca']['test']['X'].values\n",
    "y_test = data['all']['test']['y'].values\n",
    "\n",
    "print(\" Data prepared with kurtosis, all, and PCA feature sets for training, validation, and test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4976a1",
   "metadata": {},
   "source": [
    "## TASK 1 \n",
    "\n",
    "For each track in the (standardized) training data, calculate its hash value of length l using LSH. Do so for n different hash tables and add the track to its corresponding bucket in each hash table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b98b876",
   "metadata": {},
   "source": [
    "This function creates a random matrix following the Achlioptas method. Each entry is selected from {‚àö3, 0, -‚àö3} with specific probabilities to form a sparse random projection matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3d860b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_matrix(l, d): #the random matrix\n",
    "    probs = np.random.rand(l, d)\n",
    "    R = np.zeros((l, d))\n",
    "    R[probs < 1/6] = np.sqrt(3)\n",
    "    R[(probs >= 1/6) & (probs < 5/6)] = 0\n",
    "    R[probs >= 5/6] = -np.sqrt(3)\n",
    "    return R\n",
    "\n",
    "def compute_hash(R, x):\n",
    "    return tuple((np.dot(R, x) > 0).astype(int))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c6f1c",
   "metadata": {},
   "source": [
    "This function constructs n LSH tables by projecting training data using randomly generated matrices. Each data point is hashed into a bucket based on the sign of its projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b50b62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lsh_tables(X_train, n_tables=5, l=16): #lsh function \n",
    "    d = X_train.shape[1]\n",
    "    hash_tables = []\n",
    "    projection_matrices = []\n",
    "\n",
    "    for _ in range(n_tables):\n",
    "        R = generate_random_matrix(l, d)\n",
    "        table = defaultdict(list)\n",
    "        for idx, x in enumerate(X_train):\n",
    "            h = compute_hash(R, x)\n",
    "            table[h].append(idx)\n",
    "        hash_tables.append(table)\n",
    "        projection_matrices.append(R)\n",
    "\n",
    "    return hash_tables, projection_matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42142ef",
   "metadata": {},
   "source": [
    "We now apply the build_lsh_tables function to the training set with n_tables=5 and hash length l=16. This step generates the necessary hash tables and projection matrices for approximate nearest neighbor search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0adb4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_tables_all, proj_all = build_lsh_tables(X_all_train, n_tables=5, l=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f23ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_tables_pca, proj_pca = build_lsh_tables(X_pca_train, n_tables=5, l=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba8621",
   "metadata": {},
   "source": [
    "Then to proceed with Task 2 ,we agreed to first try all three options and choose the best peroforming one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b6a2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "class LSH:\n",
    "    def __init__(self, input_dim, l=10, n_tables=5, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        self.l = l\n",
    "        self.n_tables = n_tables\n",
    "        self.input_dim = input_dim\n",
    "        self.hash_tables = [defaultdict(list) for _ in range(n_tables)]\n",
    "        self.random_matrices = [self._generate_random_matrix() for _ in range(n_tables)]\n",
    "\n",
    "    def _generate_random_matrix(self):\n",
    "        # Achlioptas random projection matrix\n",
    "        prob_matrix = np.random.choice([np.sqrt(3), 0, -np.sqrt(3)], \n",
    "                                       size=(self.input_dim, self.l), \n",
    "                                       p=[1/6, 2/3, 1/6])\n",
    "        return prob_matrix\n",
    "\n",
    "    def _hash(self, R, x):\n",
    "        projection = np.dot(x, R)\n",
    "        return ''.join(['1' if val >= 0 else '0' for val in projection])\n",
    "\n",
    "    def fit(self, X):\n",
    "        # X: DataFrame or numpy matrix (rows are samples)\n",
    "        for table_idx in range(self.n_tables):\n",
    "            R = self.random_matrices[table_idx]\n",
    "            for idx, x in X.iterrows():\n",
    "                hash_code = self._hash(R, x.values)\n",
    "                self.hash_tables[table_idx][hash_code].append(idx)\n",
    "\n",
    "    def get_candidates(self, x):\n",
    "        # Return candidate similar indices from all tables\n",
    "        candidates = set()\n",
    "        for table_idx in range(self.n_tables):\n",
    "            R = self.random_matrices[table_idx]\n",
    "            hash_code = self._hash(R, x.values)\n",
    "            candidates.update(self.hash_tables[table_idx].get(hash_code, []))\n",
    "        return list(candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afc3aac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found similar tracks: [32768, 40962, 8205, 57381, 57395, 57396, 57399, 57400, 131128, 57403, 139323, 57404, 57405, 57410, 8260, 139333, 32842, 122958, 8280, 41056, 57441, 57443, 57446, 57447, 106609, 106610, 98418, 131192, 57470, 82052, 16528, 16529, 82064, 57493, 57495, 8358, 65706, 16556, 24750, 198, 139487, 57568, 139488, 33017, 257, 8451, 73990, 106772, 106773, 90408, 8490, 8491, 57642, 57644, 98614, 16695, 16703, 8514, 24904, 24913, 106834, 8531, 131416, 65880, 16733, 65887, 147808, 147810, 33129, 131438, 106864, 131443, 106879, 24971, 33185, 33192, 425, 16826, 65979, 106940, 33218, 131531, 16848, 131537, 57812, 74198, 90588, 41442, 82405, 82406, 90631, 107019, 33301, 66069, 535, 33304, 537, 33306, 123421, 123423, 123426, 16940, 33333, 66124, 66125, 123469, 123471, 605, 82528, 90721, 82531, 635, 74364, 57989, 66182, 66186, 57995, 57998, 57999, 90769, 49811, 25236, 49813, 665, 115358, 115360, 115364, 148134, 90796, 115372, 90800, 115378, 90805, 98997, 131766, 99001, 33467, 115389, 115390, 74437, 90827, 99019, 131788, 131790, 8914, 123611, 131814, 131815, 58093, 74482, 33539, 82714, 82715, 41755, 66333, 25374, 74539, 123706, 148298, 99151, 41809, 123750, 90983, 17259, 123766, 58237, 41864, 50056, 115594, 131981, 115612, 66461, 66466, 74666, 123822, 123828, 99255, 82885, 123845, 82889, 82891, 132043, 91090, 107475, 82899, 82900, 91096, 91097, 107482, 91101, 107501, 123896, 123898, 1029, 123915, 123916, 123917, 17422, 140299, 123921, 17426, 115733, 74775, 115739, 1052, 132126, 140321, 58403, 17444, 17449, 140331, 17453, 17461, 107575, 107582, 140367, 17492, 99413, 91223, 50268, 107614, 140383, 107615, 83044, 1125, 124005, 148582, 148592, 148600, 1147, 1149, 50312, 148618, 148621, 148623, 50320, 148625, 1179, 74910, 99493, 74919, 91325, 115916, 99536, 50389, 107744, 107745, 66788, 58604, 58605, 66804, 66805, 66806, 91421, 1311, 42276, 91435, 9516, 148782, 66866, 66871, 99639, 140601, 1339, 42311, 66889, 1363, 34137, 66910, 66913, 34149, 66923, 50541, 116078, 34189, 34198, 91564, 66993, 17841, 50611, 66998, 9655, 66999, 42427, 132547, 67012, 67014, 34256, 75220, 75225, 75226, 75227, 17891, 17893, 17895, 42476, 42478, 42479, 148980, 148981, 42486, 148982, 1528, 140792, 17914, 148983, 148987, 17912, 75264, 75265, 75267, 75270, 148998, 1545, 75274, 75275, 1550, 1551, 108047, 1553, 1554, 75285, 124445, 75294, 42527, 42532, 42533, 140838, 34360, 132664, 50748, 132668, 9798, 116307, 116311, 124503, 116313, 91748, 9857, 116366, 9875, 124567, 50854, 50856, 83625, 83629, 83632, 83633, 83635, 108215, 149187, 108229, 26310, 91845, 91849, 34506, 1739, 59087, 42712, 91867, 42723, 42726, 42727, 91878, 9961, 83690, 42728, 91889, 83714, 9988, 108292, 9990, 108296, 91914, 132883, 18198, 18201, 108315, 108317, 91940, 132901, 1837, 26434, 116546, 59224, 59226, 91998, 59240, 1898, 1899, 1901, 42868, 42869, 67446, 67449, 67451, 67452, 67454, 67456, 10124, 10125, 10129, 133010, 75673, 75675, 149406, 149407, 149409, 149411, 67506, 67508, 67511, 67513, 42950, 51151, 124879, 124883, 67546, 67554, 59367, 67560, 59369, 67561, 18412, 124909, 116720, 116723, 83956, 116732, 18444, 133133, 67624, 59432, 10287, 26677, 26678, 59455, 124997, 141416, 26729, 51309, 84089, 92281, 116860, 116866, 51332, 149669, 116902, 116903, 116904, 84138, 84140, 133300, 133302, 10437, 133320, 84171, 35019, 67790, 133328, 149718, 149723, 10460, 108765, 18681, 108793, 18684, 18685, 10525, 84263, 51515, 10556, 10567, 76114, 76118, 59735, 76119, 35159, 35162, 76122, 51548, 35161, 51555, 92516, 51557, 125283, 76137, 92537, 92552, 108937, 108938, 92557, 108942, 108944, 108963, 108965, 43435, 76204, 18888, 117202, 27107, 100837, 43511, 59911, 76295, 141845, 141847, 141849, 141857, 84517, 84518, 84519, 125482, 51774, 117310, 117311, 100926, 35397, 59973, 10824, 27213, 27216, 10843, 43613, 125544, 76392, 125549, 125552, 51853, 51858, 133809, 10933, 10935, 10937, 101067, 92876, 92877, 101068, 92879, 92880, 92882, 76500, 101078, 117462, 76506, 101095, 19186, 19188, 76545, 76552, 27408, 84761, 11035, 11036, 101151, 101154, 101167, 19268, 142149, 150356, 93016, 68445, 93028, 43895, 93063, 134024, 19348, 109464, 125866, 52138, 109485, 27566, 109495, 109504, 35784, 142291, 109524, 142292, 142296, 142297, 142298, 142302, 142307, 109541, 109551, 52225, 60427, 117783, 44056, 44057, 52250, 11293, 142377, 142378, 60462, 142398, 150590, 126034, 117858, 109669, 27752, 35945, 27754, 35946, 117864, 142458, 142461, 52354, 52359, 52361, 52362, 27785, 11410, 11412, 109731, 44202, 142507, 134318, 44207, 142512, 19668, 19670, 19671, 134360, 44254, 68856, 52474, 142588, 52478, 126209, 52484, 11541, 60700, 118045, 60707, 36141, 118064, 44343, 44346, 60732, 44353, 52547, 44366, 109916, 52573, 85341, 52583, 19816, 11628, 11629, 52597, 11639, 3467, 77197, 93582, 3476, 93590, 3479, 60827, 3490, 3503, 3515, 44477, 3519, 3520, 11712, 85444, 85447, 85448, 150986, 11723, 101860, 3563, 3567, 3569, 151032, 134650, 19976, 19978, 3604, 36378, 60970, 36399, 118328, 60985, 69177, 118329, 60992, 126530, 61009, 36436, 110165, 11863, 77400, 110169, 110170, 151133, 28261, 151141, 151142, 118376, 118381, 126591, 36485, 69258, 3727, 52881, 110232, 11938, 93861, 93862, 52909, 52910, 36527, 143033, 85698, 85701, 126661, 85705, 85707, 143052, 77524, 77525, 69349, 69361, 69362, 77556, 151290, 143100, 143102, 143128, 102168, 143131, 143133, 85790, 12074, 118576, 134969, 134972, 134978, 110403, 110408, 94024, 85841, 44888, 3932, 135005, 44894, 110430, 135008, 118628, 3941, 3942, 3943, 3944, 3945, 3947, 3948, 20342, 44919, 20344, 44921, 135037, 118659, 3976, 3985, 118673, 12185, 44954, 118699, 85942, 85949, 126918, 4042, 126929, 118740, 69592, 20443, 20444, 20446, 20447, 20448, 94194, 94197, 126967, 12308, 94237, 45098, 69686, 94262, 94264, 69689, 4172, 69720, 127065, 12378, 151640, 45148, 151642, 151643, 110683, 127075, 127080, 4202, 127083, 127082, 28781, 127091, 4214, 110710, 4216, 110728, 37015, 37017, 37018, 61595, 143531, 45230, 151728, 127164, 118985, 69837, 69838, 69840, 4309, 53462, 127198, 127200, 127201, 20707, 78060, 119021, 86255, 86258, 94453, 94454, 94455, 4363, 110863, 78096, 78100, 37148, 37152, 69926, 127270, 37160, 69928, 69929, 78133, 86338, 53577, 110925, 127332, 61799, 127335, 61808, 4490, 135580, 151968, 37323, 119255, 20961, 20962, 20964, 21006, 86561, 70194, 70199, 143944, 4687, 4691, 62041, 53860, 4709, 111207, 4712, 111210, 53899, 4752, 4757, 4760, 4762, 4768, 4769, 21161, 78522, 86715, 78524, 21191, 21192, 29398, 62167, 53988, 127716, 127724, 127725, 37630, 54022, 29447, 29448, 54024, 119564, 62221, 86798, 119565, 119567, 54038, 54040, 29470, 70434, 54051, 70436, 144164, 70438, 144167, 70440, 54065, 29496, 111455, 111462, 62318, 45972, 13209, 136105, 136109, 127918, 54201, 46012, 46015, 46017, 95171, 95176, 46028, 95180, 86997, 95193, 152537, 95195, 95197, 95199, 152559, 46066, 78836, 29689, 95225, 95227, 95229, 95230, 152576, 152578, 46083, 46089, 5140, 87062, 54295, 54296, 111644, 5162, 13363, 13366, 46135, 111671, 111672, 54333, 87125, 111702, 152661, 111704, 87132, 87134, 5223, 5224, 62584, 46206, 111748, 29837, 29859, 119972, 29881, 62670, 111822, 136401, 136402, 70874, 70877, 128257, 5379, 5380, 95517, 70949, 70967, 38200, 87351, 30013, 95563, 21845, 21847, 144732, 30049, 54632, 111977, 120174, 120176, 30076, 30083, 112013, 30098, 46506, 13742, 71087, 71094, 71095, 128440, 95672, 95676, 21956, 21957, 21958, 13776, 30166, 128481, 71167, 136713, 136714, 22029, 120334, 136717, 87576, 22049, 71202, 30247, 54835, 63031, 63038, 13891, 54871, 54873, 112218, 71259, 120444, 63101, 120447, 145026, 63112, 120456, 63113, 145035, 145038, 145040, 120465, 38552, 30397, 128704, 128705, 128706, 79568, 120533, 38617, 120540, 71394, 71397, 79596, 71408, 14069, 112380, 104191, 14083, 46856, 14099, 14102, 14105, 79642, 30498, 63283, 71492, 79686, 22342, 79689, 22347, 104271, 71505, 38745, 79707, 38748, 137051, 22371, 63341, 63344, 112498, 14207, 128901, 14214, 14222, 96143, 63382, 63387, 63388, 137117, 63390, 104352, 63400, 63401, 63402, 63403, 71619, 145357, 55255, 55256, 128989, 79840, 79843, 30698, 137199, 137202, 137204, 137209, 137210, 71679, 71686, 30729, 14349, 79916, 79920, 14388, 22596, 22602, 55401, 79994, 71806, 79998, 71820, 14481, 71876, 80078, 145617, 137427, 137430, 137431, 137433, 80107, 71920, 104689, 71934, 55555, 71956, 39198, 14652, 104770, 63820, 14674, 47449, 137564, 80229, 80231, 39282, 47474, 47478, 6522, 47483, 72133, 14800, 72148, 96727, 14808, 63965, 55777, 55778, 47595, 47597, 113140, 137726, 137730, 113158, 80393, 39435, 39437, 39440, 64031, 64033, 6716, 55912, 55922, 55928, 113287, 113288, 129685, 129686, 105111, 23192, 129689, 129690, 105115, 129691, 105116, 96929, 96933, 47782, 137893, 6831, 6832, 137920, 6850, 56011, 137933, 137940, 137941, 96987, 31462, 154354, 88825, 88826, 47867, 154364, 88829, 154365, 88831, 72450, 137989, 137991, 15130, 23339, 129841, 15157, 88903, 56143, 56149, 88926, 88938, 88940, 113522, 72563, 113524, 113526, 121723, 154492, 121727, 113545, 113553, 80786, 72595, 15260, 72608, 72611, 129963, 97205, 105405, 64448, 64454, 23504, 48088, 48090, 48091, 48092, 138206, 121833, 72683, 72686, 72696, 113659, 72700, 97294, 72731, 48161, 130081, 138274, 138275, 138276, 138278, 138279, 138280, 39984, 154672, 138298, 138300, 31805, 138301, 138302, 130112, 64600, 97387, 138347, 138353, 15474, 138354, 146546, 23678, 64663, 31904, 138408, 138412, 48306, 64691, 64695, 122050, 40162, 56550, 105703, 23788, 40177, 40181, 138486, 15608, 89336, 97528, 97535, 32000, 32002, 15620, 81157, 15622, 32014, 122126, 122128, 138511, 154896, 122131, 7452, 146719, 7456, 48416, 146721, 146722, 122163, 122167, 113982, 64832, 122182, 56647, 7494, 122186, 56653, 56659, 56665, 105817, 130399, 130403, 155000, 130431, 130452, 40351, 40358, 105910, 155063, 89535, 48597, 73177, 40414, 32222, 73185, 130530, 73188, 73189, 64999, 138735, 138736, 24051, 122374, 122377, 122379, 7714, 56875, 97836, 130604, 56882, 40504, 40506, 114240, 147012, 147014, 147016, 130639, 97878, 122471, 130663, 130666, 97900, 97901, 73327, 15992, 73339, 15997, 155291, 155295, 48810, 16048, 16056, 48826, 7870, 7873, 40643, 32457, 32459, 48854, 57046, 48856, 147160, 57050, 147164, 147166, 147171, 147183, 130802, 147187, 147189, 130805, 122615, 122616, 122617, 122618, 114427, 130807, 114429, 122614, 89870, 65301, 89879, 130854, 122678, 130872, 122682, 40771, 40780, 130899, 40787, 147300, 147303, 40812, 40815, 49032, 57254, 130987, 122801, 122802, 147380, 147381, 16313, 32697, 147386, 24520, 98250, 131023, 131025, 49106, 147411, 16342, 106455, 114653, 139232, 40937, 40939]\n"
     ]
    }
   ],
   "source": [
    "X_train = data['kurtosis']['train']['X']\n",
    "\n",
    "# Initialize LSH with l=10 bits, n=5 tables\n",
    "lsh = LSH(input_dim=X_train.shape[1], l=10, n_tables=5, seed=42)\n",
    "\n",
    "# Fit on training data\n",
    "lsh.fit(X_train)\n",
    "\n",
    "# Example: get similar track candidates for one validation track\n",
    "x_val = data['kurtosis']['valid']['X'].iloc[0]\n",
    "candidates = lsh.get_candidates(x_val)\n",
    "print(\"Found similar tracks:\", candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42febf1a",
   "metadata": {},
   "source": [
    "### TASK 2 \n",
    "\n",
    "For each track $t_i$ in the validation data, find similar music tracks using LSH. A music track is defined as similar if it is in the same bucket as $t_i$ in one of the n hash tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acec05f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature Set     Metric  Validation Accuracy  Evaluated Samples\n",
      "0    kurtosis     cosine             0.567951               1479\n",
      "1    kurtosis  euclidean             0.559838               1479\n",
      "2         all     cosine             0.610033               1495\n",
      "3         all  euclidean             0.608027               1495\n",
      "4         pca     cosine             0.591510               1437\n",
      "5         pca  euclidean             0.593598               1437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from collections import Counter\n",
    "\n",
    "# Evaluation function for this task \n",
    "def evaluate_lsh_classifier(X_val, y_val, X_train, y_train, l=16, n_tables=5, k=5, metric='cosine'):\n",
    "    lsh = LSH(input_dim=X_train.shape[1], l=l, n_tables=n_tables, seed=42)\n",
    "    lsh.fit(X_train)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for idx, x_val in X_val.iterrows():\n",
    "        candidates = lsh.get_candidates(x_val)\n",
    "        if not candidates:\n",
    "            continue\n",
    "\n",
    "        X_candidates = X_train.loc[candidates]\n",
    "        y_candidates = y_train.loc[candidates]\n",
    "\n",
    "        # Compute distances\n",
    "        if metric == 'cosine':\n",
    "            dists = cosine_distances([x_val.values], X_candidates.values)[0]\n",
    "        elif metric == 'euclidean':\n",
    "            dists = euclidean_distances([x_val.values], X_candidates.values)[0]\n",
    "        else:\n",
    "            raise ValueError(\"Unknown metric\")\n",
    "\n",
    "        nearest_indices = np.argsort(dists)[:k]\n",
    "        top_k_labels = y_candidates.iloc[nearest_indices]\n",
    "\n",
    "        prediction = Counter(top_k_labels).most_common(1)[0][0]\n",
    "\n",
    "        if prediction == y_val.loc[idx]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return accuracy, total\n",
    "\n",
    "# Evaluate all three variants\n",
    "results = []\n",
    "for variant in ['kurtosis', 'all', 'pca']:\n",
    "    for metric in ['cosine', 'euclidean']:\n",
    "        X_train = data[variant]['train']['X']\n",
    "        y_train = data[variant]['train']['y']\n",
    "        X_val = data[variant]['valid']['X']\n",
    "        y_val = data[variant]['valid']['y']\n",
    "\n",
    "        acc, total = evaluate_lsh_classifier(X_val, y_val, X_train, y_train,\n",
    "                                             l=16, n_tables=5, k=5, metric=metric)\n",
    "        results.append((variant, metric, acc, total))\n",
    "\n",
    "import pandas as pd\n",
    "df_results = pd.DataFrame(results, columns=['Feature Set', 'Metric', 'Validation Accuracy', 'Evaluated Samples'])\n",
    "print(df_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cbbc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0224a1",
   "metadata": {},
   "source": [
    "Given a query vector x, this function(def find_candidate_neighbors) searches through the LSH tables to find candidate neighbors. It hashes the query using the same projection matrices and retrieves all items from the corresponding buckets across all hash tables.\n",
    "Then After retrieving candidate neighbors, this function determines the genre of a track by performing a majority vote among the k nearest neighbors. It considers the genres of the closest tracks to predict the genre of the query track.\n",
    "And Finally the function (evaluate_on_validation_set)assesses the performance of the LSH-based classifier by predicting genres for the validation set and comparing them to the true labels. It computes the accuracy of the predictions to gauge the effectiveness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e1de15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lsh_tables(X_train, n_tables=5, l=16, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    input_dim = X_train.shape[1]\n",
    "    hash_tables = [defaultdict(list) for _ in range(n_tables)]\n",
    "    projection_matrices = [\n",
    "        np.random.choice([np.sqrt(3), 0, -np.sqrt(3)],\n",
    "                         size=(input_dim, l), p=[1/6, 2/3, 1/6])\n",
    "        for _ in range(n_tables)\n",
    "    ]\n",
    "    for table_idx in range(n_tables):\n",
    "        R = projection_matrices[table_idx]\n",
    "        for idx, x in X_train.iterrows():\n",
    "            proj = np.dot(x.values, R)\n",
    "            hash_code = ''.join(['1' if val >= 0 else '0' for val in proj])\n",
    "            hash_tables[table_idx][hash_code].append(idx)\n",
    "    return hash_tables, projection_matrices\n",
    "\n",
    "def find_candidate_neighbors(x_val, hash_tables, projection_matrices):\n",
    "    candidates = set()\n",
    "    for table_idx in range(len(hash_tables)):\n",
    "        R = projection_matrices[table_idx]\n",
    "        proj = np.dot(x_val.values, R)\n",
    "        hash_code = ''.join(['1' if val >= 0 else '0' for val in proj])\n",
    "        candidates.update(hash_tables[table_idx].get(hash_code, []))\n",
    "    return list(candidates)\n",
    "\n",
    "def predict_genre_for_track(x_val, X_train, y_train, hash_tables, projection_matrices,\n",
    "                            k=5, metric='cosine', fallback_genre='Rock'):\n",
    "    candidate_idxs = find_candidate_neighbors(x_val, hash_tables, projection_matrices)\n",
    "    if not candidate_idxs:\n",
    "        return fallback_genre\n",
    "    X_candidates = X_train.loc[candidate_idxs]\n",
    "    y_candidates = y_train.loc[candidate_idxs]\n",
    "    if metric == 'cosine':\n",
    "        dists = cosine_distances([x_val.values], X_candidates.values)[0]\n",
    "    elif metric == 'euclidean':\n",
    "        dists = euclidean_distances([x_val.values], X_candidates.values)[0]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown metric\")\n",
    "    nearest_indices = np.argsort(dists)[:min(k, len(candidate_idxs))]\n",
    "    top_k_labels = y_candidates.iloc[nearest_indices]\n",
    "    return Counter(top_k_labels).most_common(1)[0][0]\n",
    "\n",
    "def evaluate_on_validation_set(X_train, y_train, X_val, y_val, l, n_tables, k, metric):\n",
    "    fallback_genre = y_train.mode()[0]\n",
    "    hash_tables, projection_matrices = build_lsh_tables(X_train, n_tables=n_tables, l=l)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for idx, x in X_val.iterrows():\n",
    "        pred = predict_genre_for_track(x, X_train, y_train,\n",
    "                                       hash_tables, projection_matrices,\n",
    "                                       k=k, metric=metric,\n",
    "                                       fallback_genre=fallback_genre)\n",
    "        if pred == y_val.loc[idx]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = correct / total if total > 0 else 0\n",
    "    return acc, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d3025",
   "metadata": {},
   "source": [
    "Here we performed a Grid Search.In this section, we systematically experiment with various combinations of hyperparameters (l, n_tables, k) and similarity metrics (cosine, euclidean) to identify the configuration that yields the highest validation accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a01414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Evaluating feature set: KURTOSIS\n",
      "\n",
      "üîç Evaluating feature set: ALL\n",
      "\n",
      "üîç Evaluating feature set: PCA\n",
      "\n",
      " Validation runs per feature set:\n",
      "Feature Set\n",
      "pca         54\n",
      "all         54\n",
      "kurtosis    54\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Top results for KURTOSIS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Set</th>\n",
       "      <th>l</th>\n",
       "      <th>n_tables</th>\n",
       "      <th>k</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Evaluated Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kurtosis</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.597324</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>kurtosis</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.588629</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kurtosis</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.585284</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kurtosis</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.585284</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>kurtosis</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.576589</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature Set   l  n_tables   k     Metric  Validation Accuracy  \\\n",
       "16    kurtosis  10         8  10     cosine             0.597324   \n",
       "34    kurtosis  16         8  10     cosine             0.588629   \n",
       "10    kurtosis  10         5  10     cosine             0.585284   \n",
       "17    kurtosis  10         8  10  euclidean             0.585284   \n",
       "35    kurtosis  16         8  10  euclidean             0.576589   \n",
       "\n",
       "    Evaluated Samples  \n",
       "16               1495  \n",
       "34               1495  \n",
       "10               1495  \n",
       "17               1495  \n",
       "35               1495  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top results for ALL:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Set</th>\n",
       "      <th>l</th>\n",
       "      <th>n_tables</th>\n",
       "      <th>k</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Evaluated Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>all</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.620736</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>all</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.620736</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>all</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.620067</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>all</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.620067</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>all</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.620067</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature Set   l  n_tables   k     Metric  Validation Accuracy  \\\n",
       "59          all  10         3  10  euclidean             0.620736   \n",
       "77          all  16         3  10  euclidean             0.620736   \n",
       "100         all  24         5  10     cosine             0.620067   \n",
       "94          all  24         3  10     cosine             0.620067   \n",
       "106         all  24         8  10     cosine             0.620067   \n",
       "\n",
       "     Evaluated Samples  \n",
       "59                1495  \n",
       "77                1495  \n",
       "100               1495  \n",
       "94                1495  \n",
       "106               1495  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top results for PCA:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Set</th>\n",
       "      <th>l</th>\n",
       "      <th>n_tables</th>\n",
       "      <th>k</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Evaluated Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>pca</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.703010</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>pca</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.698997</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>pca</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.694314</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>pca</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>pca</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>cosine</td>\n",
       "      <td>0.684950</td>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature Set   l  n_tables   k     Metric  Validation Accuracy  \\\n",
       "124         pca  10         8  10     cosine             0.703010   \n",
       "119         pca  10         5  10  euclidean             0.698997   \n",
       "118         pca  10         5  10     cosine             0.694314   \n",
       "125         pca  10         8  10  euclidean             0.692308   \n",
       "122         pca  10         8   5     cosine             0.684950   \n",
       "\n",
       "     Evaluated Samples  \n",
       "124               1495  \n",
       "119               1495  \n",
       "118               1495  \n",
       "125               1495  \n",
       "122               1495  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1726.35 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "l_values = [10, 16, 24]\n",
    "n_values = [3, 5, 8]\n",
    "k_values = [3, 5, 10]\n",
    "metrics = ['cosine', 'euclidean']\n",
    "param_grid = list(itertools.product(l_values, n_values, k_values, metrics))\n",
    "\n",
    "# Run validation for all feature sets \n",
    "val_results = []\n",
    "\n",
    "for variant in ['kurtosis', 'all', 'pca']:\n",
    "    print(f\"\\nüîç Evaluating feature set: {variant.upper()}\")\n",
    "    X_train = data[variant]['train']['X']\n",
    "    y_train = data[variant]['train']['y']\n",
    "    X_val = data[variant]['valid']['X']\n",
    "    y_val = data[variant]['valid']['y']\n",
    "\n",
    "    for l, n_tables, k, metric in param_grid:\n",
    "        acc, total = evaluate_on_validation_set(X_train, y_train, X_val, y_val,\n",
    "                                                l=l, n_tables=n_tables, k=k, metric=metric)\n",
    "        val_results.append((variant, l, n_tables, k, metric, acc, total))\n",
    "\n",
    "# Create The results to sort them \n",
    "df_val_results = pd.DataFrame(val_results, columns=[\n",
    "    'Feature Set', 'l', 'n_tables', 'k', 'Metric', 'Validation Accuracy', 'Evaluated Samples'\n",
    "])\n",
    "df_val_results = df_val_results.sort_values(by='Validation Accuracy', ascending=False)\n",
    "\n",
    "#  Confirm everything ran...I had a problem with the loop and only the option with the best performance run so i needed to add this line \n",
    "print(\"\\n Validation runs per feature set:\")\n",
    "print(df_val_results['Feature Set'].value_counts())  # Should be 54 each\n",
    "\n",
    "#  Show best config per feature set\n",
    "for variant in ['kurtosis', 'all', 'pca']:\n",
    "    print(f\"\\n Top results for {variant.upper()}:\")\n",
    "    display(df_val_results[df_val_results['Feature Set'] == variant].sort_values(by='Validation Accuracy', ascending=False).head(5)) \n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31647fab",
   "metadata": {},
   "source": [
    "Now to Complete Task Two, the best combination I used it for this next step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed81d033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 458 has 110 similar tracks (same bucket):\n",
      "[76293, 144397, 117774, 93725, 144422, 56885, 3638, 125496, 57410, 32839]\n",
      "---\n",
      "Track 583 has 249 similar tracks (same bucket):\n",
      "[82440, 71689, 26633, 1548, 117774, 1551, 8209, 14871, 132121, 14874]\n",
      "---\n",
      "Track 584 has 300 similar tracks (same bucket):\n",
      "[151045, 109063, 137736, 144391, 13834, 144393, 144397, 14862, 151053, 89617]\n",
      "---\n",
      "Track 585 has 353 similar tracks (same bucket):\n",
      "[61440, 14347, 38954, 94256, 69683, 43062, 69686, 139333, 67654, 67659]\n",
      "---\n",
      "Track 603 has 280 similar tracks (same bucket):\n",
      "[19457, 70658, 76295, 6664, 32776, 15369, 37388, 123917, 126991, 126483]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Load the best configuration\n",
    "X_train = data['pca']['train']['X']\n",
    "X_val = data['pca']['valid']['X']\n",
    "\n",
    "# Step 1: Build hash tables\n",
    "hash_tables, projection_matrices = build_lsh_tables(X_train, n_tables=8, l=10)\n",
    "\n",
    "# Step 2: Find similar tracks for each validation track\n",
    "similar_tracks_dict = {}\n",
    "\n",
    "for idx, x_val in X_val.iterrows():\n",
    "    similar = find_candidate_neighbors(x_val, hash_tables, projection_matrices)\n",
    "    similar_tracks_dict[idx] = similar\n",
    "\n",
    "# Step 3: Print examples\n",
    "for track_id, neighbors in list(similar_tracks_dict.items())[:5]:  # only print first 5\n",
    "    print(f\"Track {track_id} has {len(neighbors)} similar tracks (same bucket):\")\n",
    "    print(neighbors[:10])  # Show up to 10 neighbors\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92fa728",
   "metadata": {},
   "source": [
    "### TASK 3 \n",
    "\n",
    "Calculate the actual similarity of $t_i$ to all similar music tracks based on their feature vectors and some similarity metric m. As a genre prediction for ti, use the majority genre of its k-nearest-neighbours defined as the k most similar music tracks to $t_i$ as ranked by m found in the same bucket as $t_i$.\n",
    "\n",
    "Note: Think about how to treat cases where there are less then k music tracks similar to $t_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5df5eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "from collections import Counter\n",
    "\n",
    "def predict_genre_for_track(x_val, X_train, y_train, hash_tables, projection_matrices,\n",
    "                            k=10, metric='cosine', fallback_genre='Rock'):\n",
    "    candidate_idxs = find_candidate_neighbors(x_val, hash_tables, projection_matrices)\n",
    "\n",
    "    if not candidate_idxs:\n",
    "        return fallback_genre\n",
    "\n",
    "    X_candidates = X_train.loc[candidate_idxs]\n",
    "    y_candidates = y_train.loc[candidate_idxs]\n",
    "\n",
    "    # Compute similarity\n",
    "    if metric == 'cosine':\n",
    "        dists = cosine_distances([x_val.values], X_candidates.values)[0]\n",
    "    elif metric == 'euclidean':\n",
    "        dists = euclidean_distances([x_val.values], X_candidates.values)[0]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid metric\")\n",
    "\n",
    "    # Rank and get top k (or all if fewer than k)\n",
    "    nearest_indices = np.argsort(dists)[:min(k, len(candidate_idxs))]\n",
    "    top_k_labels = y_candidates.iloc[nearest_indices]\n",
    "\n",
    "    # Majority vote\n",
    "    predicted_genre = Counter(top_k_labels).most_common(1)[0][0]\n",
    "    return predicted_genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "767e4eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Validation accuracy using The method on task 2 : 0.7030 (1051/1495)\n"
     ]
    }
   ],
   "source": [
    "# Load best config\n",
    "X_train = data['pca']['train']['X']\n",
    "y_train = data['pca']['train']['y']\n",
    "X_val = data['pca']['valid']['X']\n",
    "y_val = data['pca']['valid']['y']\n",
    "l, n_tables, k, metric = 10, 8, 10, 'cosine'\n",
    "fallback_genre = y_train.mode()[0]\n",
    "\n",
    "# Build hash tables from training data\n",
    "hash_tables, projection_matrices = build_lsh_tables(X_train, n_tables=n_tables, l=l)\n",
    "\n",
    "# Predict for all validation samples\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for idx, x_val in X_val.iterrows():\n",
    "    pred = predict_genre_for_track(x_val, X_train, y_train,\n",
    "                                   hash_tables, projection_matrices,\n",
    "                                   k=k, metric=metric,\n",
    "                                   fallback_genre=fallback_genre)\n",
    "    if pred == y_val.loc[idx]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "val_acc = correct / total\n",
    "print(f\" Validation accuracy using The method on task 2 : {val_acc:.4f} ({correct}/{total})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee6461",
   "metadata": {},
   "source": [
    "We apply the evaluate_accuracy function to the validation dataset to measure how well our LSH-based classifier performs.And we checked the hyperparameter tuning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46d41604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final validation accuracy: 0.7030 (1051/1495 correct)\n"
     ]
    }
   ],
   "source": [
    "# Use best performing config from Task 2\n",
    "X_train = data['pca']['train']['X']\n",
    "y_train = data['pca']['train']['y']\n",
    "X_val = data['pca']['valid']['X']\n",
    "y_val = data['pca']['valid']['y']\n",
    "\n",
    "l = 10\n",
    "n_tables = 8\n",
    "k = 10\n",
    "metric = 'cosine'\n",
    "fallback_genre = y_train.mode()[0] #This are the best parameters/combinations\n",
    "\n",
    "# Build LSH hash tables\n",
    "hash_tables, projection_matrices = build_lsh_tables(X_train, n_tables=n_tables, l=l)\n",
    "\n",
    "# Run prediction on validation set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for idx, x_val in X_val.iterrows():\n",
    "    pred = predict_genre_for_track(x_val, X_train, y_train,\n",
    "                                   hash_tables, projection_matrices,\n",
    "                                   k=k, metric=metric,\n",
    "                                   fallback_genre=fallback_genre)\n",
    "    if pred == y_val.loc[idx]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "val_acc = correct / total\n",
    "print(f\" Final validation accuracy: {val_acc:.4f} ({correct}/{total} correct)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f38488",
   "metadata": {},
   "source": [
    "### Task 4 \n",
    "\n",
    "Evaluate the classification accuracy of your algorithm on the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1146471",
   "metadata": {},
   "source": [
    "**Training the final model with optimal hyperparameters **\n",
    "After determining the best hyperparameter configuration, we retrain the LSH model using both the training and validation datasets. This approach leverages all available labeled data to enhance the model's generalization ability before evaluating it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44640e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final test set accuracy: 0.6853 (1052/1535 correct)\n"
     ]
    }
   ],
   "source": [
    "# Combine training + validation for final training set\n",
    "X_train_val = pd.concat([data['pca']['train']['X'], data['pca']['valid']['X']])\n",
    "y_train_val = pd.concat([data['pca']['train']['y'], data['pca']['valid']['y']])\n",
    "\n",
    "# Test set\n",
    "X_test = data['pca']['test']['X']\n",
    "y_test = data['pca']['test']['y']\n",
    "\n",
    "# Best parameters\n",
    "l = 10\n",
    "n_tables = 8\n",
    "k = 10\n",
    "metric = 'cosine'\n",
    "fallback_genre = y_train_val.mode()[0]\n",
    "\n",
    "# Build final LSH hash tables\n",
    "hash_tables, projection_matrices = build_lsh_tables(X_train_val, n_tables=n_tables, l=l)\n",
    "\n",
    "# Evaluate on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for idx, x_test in X_test.iterrows():\n",
    "    pred = predict_genre_for_track(x_test, X_train_val, y_train_val,\n",
    "                                   hash_tables, projection_matrices,\n",
    "                                   k=k, metric=metric,\n",
    "                                   fallback_genre=fallback_genre)\n",
    "    if pred == y_test.loc[idx]:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\" Final test set accuracy: {test_acc:.4f} ({correct}/{total} correct)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df85408a",
   "metadata": {},
   "source": [
    "**Testing the final LSH model **\n",
    "We assess the performance of our optimized LSH-based classifier on the test dataset to estimate its generalization to unseen data. The test accuracy serves as an indicator of the model's effectiveness in real-world scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
